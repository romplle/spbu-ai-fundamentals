{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интерфейсы scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, OneToOneFeatureMixin\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator\n",
    "\n",
    "Для примера построим простой estimator, который в перспективе будет вычитать из признаков их среднее значение и после сдвигать признаки на заранее заданную константу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubtractMeanAndShiftEstimator(BaseEstimator):\n",
    "    def __init__(self, shift=0.):\n",
    "        self.shift: float = shift\n",
    "        self.means_: NDArray = None  # we add a trailing underscore for parameters which will be learnt in fit()\n",
    "\n",
    "    def fit(self, X: NDArray, y: NDArray = None):\n",
    "        # y is ignored here\n",
    "        self.means_ = X.mean(axis=0)  # the first axis corresponds to samples by default\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SubtractMeanAndShiftEstimator(shift=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `get_params()` реализован в `BaseEstimator`, и мы можем сразу использовать его для получения гиперпараметров модели. Это возможно, так как единственный гиперпараметр `shift` был передан как явное ключевое слово в контрукторе\n",
    "\n",
    "Обратите внимание, что соответствующий аттрибут класса должен совпадать с ключевым словом: `self.shift = shift`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично мы можем использовать `set_params()` для задания значений гиперпараметров. Этот метод пригодится при поиске оптимальных значений гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.set_params(shift=5)\n",
    "m.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 10],\n",
    "    [3, 30],\n",
    "    [2, 20],\n",
    "])\n",
    "y = np.array([\n",
    "    [ 0, -8],\n",
    "    [ 2, 10],\n",
    "    [ 1,  1],\n",
    "])\n",
    "m.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn есть класс sklearn.base.OutlierMixin, который позволяет реализовывать кастомные классы для определения выбросов.\n",
    "Он добавляет:\n",
    "- атрибут _estimator_type, по умолчанию outlier_detector\n",
    "- fit_predict.\n",
    "\n",
    "Метод fit() работает в формате без учителя, predict же должен классифицировать данные на аутлаеры (возвращать для них -1) и обыычные данные (возвращать 1). Для классификации используется отсечка по порогу предсказаний, полученных внутренним.\n",
    "Во встроенных методах функция оценки доступна с помощью метода `score_samples`, в то время как порог можно задать параметром `contamination`. \n",
    "Например, для гауссовских данных можно использовать sklearn.covariance.EllipticEnvelope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте свой эстиматор с использованием sklearn.base.OutlierMixin, который будет определять выбросы на основе интерквартильного размаха. \n",
    "Он должен возвращать один столбец с 1 и -1, а также позволять задавать порог для квантиля, определяющего размах. Не забудьте, что он должен быть двухсторонним.\n",
    "Ваш эстиматор должен работать и для датафреймов, и для numpy массивов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, OutlierMixin\n",
    "class MyEstimator(BaseEstimator, OutlierMixin):\n",
    "     def __init__(self,factor=1.5):\n",
    "        self.factor = factor\n",
    "     def fit(self, X, y=None):\n",
    "         self.is_fitted_ = True\n",
    "         X = pd.DataFrame(X.copy())\n",
    "         q1 = X.quantile(0.35)\n",
    "         q3 = X.quantile(0.55)\n",
    "         iqr = q3 - q1\n",
    "         self._lower_bound = q1 - (self.factor * iqr)\n",
    "         self._upper_bound = q3 + (self.factor * iqr)\n",
    "         print(X.min(axis=0))\n",
    "         return self\n",
    "         \n",
    "     def predict(self, X):\n",
    "         temp = np.ones(len(X))\n",
    "         temp[(X > self._lower_bound.values).all(axis=1) & (X < self._upper_bound.values).all(axis=1)] = -1\n",
    "         return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MyEstimator()\n",
    "true_cov = np.array([[.8, .3],\n",
    "                     [.3, .4]])\n",
    "X = np.random.RandomState(42).multivariate_normal(mean=[0, 0],\n",
    "                                                 cov=true_cov,\n",
    "                                                 size=500)\n",
    "e = estimator.fit(X)\n",
    "#pred = estimator.predict(X)\n",
    "e._lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e._upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor\n",
    "\n",
    "Рассмотрим тот же класс, но добавим к нему методы `predict()` и `score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubtractMeanAndShiftPredictor(BaseEstimator):\n",
    "    def __init__(self, shift=0.):\n",
    "        self.shift: float = shift\n",
    "        self.means_: NDArray = None  # we add a trailing underscore for parameters which will be learnt in fit()\n",
    "\n",
    "    def fit(self, X: NDArray, y: NDArray = None):\n",
    "        # y is ignored here\n",
    "        self.means_ = X.mean(axis=0)  # the first axis corresponds to samples by default\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: NDArray) -> NDArray:\n",
    "        e = np.ones((X.shape[0], 1))\n",
    "        return X -  e @ self.means_.reshape(-1, 1).T + self.shift\n",
    "\n",
    "    def score(self, X: NDArray, y: NDArray) -> float:\n",
    "        return r2_score(y, self.predict(X))  # R2 \\in (-\\infty; 1] is the coefficient of determination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы специально добавили небольшое отклонение в y, наш R2 чуть меньше 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SubtractMeanAndShiftPredictor(shift=1)\n",
    "model.fit(X)\n",
    "model.predict(X)\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    "Рассмотрим тот же класс, но добавим к нему метод `transform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubtractMeanAndShiftTransformer(BaseEstimator, OneToOneFeatureMixin, TransformerMixin):\n",
    "    def __init__(self, shift=0.):\n",
    "        self.shift: float = shift\n",
    "        self.means_: NDArray = None  # we add a trailing underscore for parameters which will be learnt in fit()\n",
    "\n",
    "    def fit(self, X: NDArray, y: NDArray = None):\n",
    "        # y is ignored here\n",
    "        self.means_ = X.mean(axis=0)  # the first axis corresponds to samples by default\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: NDArray) -> NDArray:\n",
    "        e = np.ones((X.shape[0], 1))\n",
    "        return X -  e @ self.means_.reshape(-1, 1).T + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = SubtractMeanAndShiftTransformer(shift=5)\n",
    "t.fit(X)\n",
    "t.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы добавили `TransformerMixin`, мы можем использовать метод `fit_transform()`, не реализуя его явно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично мы можем использовать метод `get_feature_names_out()`, так как мы добавили `OneToOneFeatureMixin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.get_feature_names_out(input_features=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Используем датасет с домами как пример. Вспомним, что мы делали в прошлый раз, и попробуем заполнить пропущенные значения в некоторых числовызх столбцах.\n",
    "Для этого используем трансформер по столбцам. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(cfg['house_pricing']['train_dataset'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию, только указанные столбцы трансформируются и возвращаются (remainder=`drop`). Мы же сделаем так, чтобы все остальные столбцы тоже возвращались, просто с ними бы ничего не делалось. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [('mean_impute', SimpleImputer(strategy='mean'), ['SalePrice', 'LotArea', 'WoodDeckSF',  'MasVnrArea'])], \n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "ct.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у датасета появятсся столбцы, которые не были представлены во время fit (даже среди тех, что не трансформировались), то они будут выкинуты на этапе transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temp\"] = 0\n",
    "ct.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Перейдите к медианному заполнению пропусков. Проверьте, что результаты, полученные с помощью трансформации, соответствуют преобразованию напрямую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Добавьте еще нормализатор для LotFrontage, LotArea и запустите в ColumnTransformer. Обучите его и примените."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn располагает большим количеством встроенных трансформеров. Соответствующие трансформеры есть и для категориальных фичей (более подробно рассмотрим этот тип чуть позже). Например, известное нам бинарное кодирование можно проводить с помощью OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('median_impute', SimpleImputer(strategy='mean'), ['SalePrice', 'LotArea', 'WoodDeckSF',  'MasVnrArea']),\n",
    "        (\"one_hot_encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"MSZoning\", \"SaleType\", \"SaleCondition\"]),\n",
    "    ], \n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "ct.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.set_output(transform='pandas')\n",
    "ct.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выбора столбцов можно создавать make_selector, например, по выбору численных и категориальных значений. \n",
    "\n",
    "**Доп. задание**. Сделайте трансформер для OneHotEncoder на основе make_selector так, чтобы выбирать все нечисловые столбцы. Сколько столбцов получается после трансформации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "С помощью Pipeline мы можем производить последовательную обработку данных и выполнять предсказание в конце"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 10],\n",
    "    [3, 30],\n",
    "    [2, 20],\n",
    "])\n",
    "y = np.array([\n",
    "    [0],\n",
    "    [2],\n",
    "    [1],\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"shifter\", SubtractMeanAndShiftTransformer(shift=5)),\n",
    "    (\"regressor\", LinearRegression()),\n",
    "])\n",
    "...\n",
    "pipeline.fit(X, y)\n",
    "y_pred = pipeline.predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline хранит последовательные Estimators в аттрибуте `steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейти к объекту i-го Estimator можно напрямую через `pipeline[i]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline[1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как Pipeline сам является Estimator, мы можем увидеть список его параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, параметры промежуточных Estimator указаны как `<estimator>__<parameter>`. Следовательно, мы можем изменить параметры любого промежуточного Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.set_params(shifter__shift=10)\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Задание**: Создайте пайплайн по преобразованию чсиленных столбцов, содержащий импьютер и скейлер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте новый трансформер, который для категориальных столбцов будет заполнять пропущенные значения наиболее часто встречаюмшщимся или новой категорией (сделайте параметром). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте пайплайн по преобразованию категориальных столбцов, содержащий ваш импьютер и OneHotEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: Создайте ColumnTransformer, который будет содержать в себе два вышеуказанных пайплайна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Доп.задание**: Используйте для комбинации результатов двух отдельных трансформеров FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b3714695f2307aafe7da52bf6e53e38bc5469a267534973be7d21c816457eaf"
  },
  "kernelspec": {
   "display_name": "ml_2025",
   "language": "python",
   "name": "ml_2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
